{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLZlpLIrMtNAZjWE5Cu+Ft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushXRane/Genre-Classifier/blob/main/Genre_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"dataset.csv\", error_bad_lines = False)\n",
        "selected_genres = ['classical', 'emo', 'funk', 'grunge', 'hard rock', 'metal', 'indian', 'hip hop', 'pop', 'rock', 'acoustic']\n",
        "df = df[df['track_genre'].isin(selected_genres)]\n",
        "\n",
        "df = df.drop(columns = ['track_id', 'album_name'])\n",
        "df"
      ],
      "metadata": {
        "id": "zQzr-r-taQi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['label_encoded'] = label_encoder.fit_transform(df['track_genre'])\n",
        "\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "bwg983fnHczh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yBdx_TrAQ_8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "selected_labels = df[['popularity', 'duration_ms', 'danceability', 'energy', 'key', 'loudness',\n",
        "    'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness',\n",
        "    'valence', 'tempo', 'time_signature', 'label_encoded']]\n",
        "correlation = selected_labels.corr()\n",
        "label_correlation = correlation['label_encoded']\n",
        "label_correlation\n"
      ],
      "metadata": {
        "id": "y0s7r-k9Cf51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_numeric = df.drop(columns = ['label_encoded', 'artists', 'track_name'])\n",
        "y = df['label_encoded']\n",
        "X_numeric\n",
        "type(X_numeric)"
      ],
      "metadata": {
        "id": "PY3ExIL2hCKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8_cs9K09PgNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=1000)\n",
        "text_features = df['artists'] + ' ' + df['track_name']\n",
        "text_features_numeric = vectorizer.fit_transform(text_features)\n",
        "text_features_numeric.shape\n",
        "\n",
        "type(X_numeric)\n",
        "type(text_features_numeric)\n",
        "\n",
        "X = pd.concat([X_numeric, pd.DataFrame(text_features_numeric.toarray())], axis=1)\n",
        "X\n",
        "\n",
        "#X = hstack([X_numeric, text_features_numeric])\n",
        "#X_combined = pd.concat([X_numeric, csr_matrix(text_features_numeric)], axis=1)\n",
        "\n",
        "#X_numeric_sparse = csr_matrix(X_numeric)\n",
        "\n",
        "#type(X_numeric_sparse)\n",
        "\n",
        "X = X.dropna()\n",
        "X\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nmtSyeJqOaE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
        "X_train, X_val, y_train, y_val =  train_test_split(X_train, y_train, test_size = 0.25, random_state = 1)\n",
        "X_train\n",
        "y_train\n"
      ],
      "metadata": {
        "id": "oz_gTSgwebYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "svm.predict(X_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "y_val_pred = svm.predict(X_val)\n",
        "\n",
        "print(classification_report(y_val_pred, y_val))\n",
        "svm.predict(X_train.getrow(0))\n",
        "\n",
        "accuracy_score(y_pred, y_test)\n",
        "\n",
        "new_data = svm.predict({'artists': [\"Elvis Presley\"], 'track_name': ['Hound Dog'],'popularity': [66], 'duration_ms': [136026], 'danceability': [.494], 'energy': 0.756, 'key': 0, 'loudness': -8.492,\n",
        "    'mode':1, 'speechiness': 0.0499, 'acousticness':0.733, 'instrumentalness': 0.00505, 'liveness':0.76,\n",
        "    'valence':0.949, 'tempo':86.895, 'time_signature': 4 })"
      ],
      "metadata": {
        "id": "KzRP0xzXYszS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mJUXdoKgj2If"
      }
    }
  ]
}